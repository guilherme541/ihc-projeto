# Planejamento de Avaliação de Usabilidade - Método DECIDE

| DECIDE | Descrição |
| :---: | :---- |
| **D** | **Determinar os objetivos da avaliação:**<br><br>**Objetivo Geral:**<br>Julgar a qualidade de uso da interface de testes e validação de modelos de IA e identificar problemas de interação que prejudiquem a experiência das personas (Paulo Andrade, Ricardo Santos e Fernanda Costa).<br><br>**Objetivos Específicos:**<br>1. Validar os fluxos de interação definidos nos cenários (ex: "Configurar e Executar Modelo", "Visualizar e Exportar Relatórios") e verificar se são eficientes e fáceis de aprender.<br>2. Identificar problemas de usabilidade na interface, como falta de feedback durante o processamento, inconsistências visuais ou caminhos confusos entre as telas.<br>3. Medir a eficácia dos usuários na conclusão de tarefas-chave definidas no Mapa de Objetivos (ex: "Upload e teste de modelo", "Comparação de métricas", "Exportação de relatórios CSV").<br>4. Coletar dados qualitativos (opiniões, frustrações, sugestões) para guiar o reprojeto da interface e priorizar melhorias.<br>5. Avaliar se as métricas técnicas (precisão, recall, F1-score, mAP) são apresentadas de forma compreensível para diferentes perfis de usuário. |
| **E** | **Explorar as perguntas a serem respondidas:**<br><br>Para operacionalizar os objetivos, buscaremos responder perguntas específicas para cada persona:<br><br>**Para o Engenheiro de ML - Paulo Andrade (Cenário: "Análise de Modelos"):**<br>1. O usuário consegue fazer o upload do arquivo .pt do modelo de forma intuitiva?<br>2. O fluxo de seleção de dataset (imagem/vídeo) e início dos testes é claro?<br>3. Como o usuário reage ao status "Analisando... Isso pode levar alguns instantes"? O feedback é suficiente?<br>4. O usuário consegue interpretar os gráficos de métricas apresentados após a execução?<br>5. A funcionalidade de filtrar/ordenar métricas atende às necessidades de análise técnica?<br>6. O tempo de resposta do sistema é adequado para a expectativa do usuário?<br>7. A interface permite configurar adequadamente o limite de confiança e o uso de GPU?<br><br>**Para o Gerente de Segurança - Ricardo Santos (Cenário: "Painel de Resultados"):**<br>1. O usuário consegue acessar e selecionar relatórios existentes facilmente?<br>2. Os dashboards com métricas de desempenho são compreensíveis para um perfil não-técnico?<br>3. A tradução de métricas técnicas para indicadores de segurança operacional é clara?<br>4. O processo de exportação do relatório em CSV é intuitivo?<br>5. O que o usuário faz quando não encontra o relatório que procura?<br>6. As informações apresentadas são suficientes para tomar decisões sobre aprovação de modelos?<br><br>**Para a Gestora de Projetos - Fernanda Costa (Cenário: "Painel de Resultados - Visão Executiva"):**<br>1. Os relatórios consolidados são facilmente acessíveis?<br>2. Os gráficos e resumos executivos comunicam o desempenho dos modelos de forma clara?<br>3. A interface facilita a preparação de apresentações para stakeholders?<br>4. O usuário consegue comparar diferentes modelos testados em períodos distintos?<br>5. As informações são suficientes para justificar decisões de investimento?<br>6. O tempo necessário para consultar e exportar relatórios é adequado para reuniões executivas? |
| **C** | **Escolher os métodos de avaliação:**<br><br>Conforme os princípios de avaliação de IHC, usaremos uma abordagem mista:<br><br>**1. Testes com Usuários (Método de Observação e Investigação):**<br>Recrutaremos usuários reais que se encaixam nas personas (Paulo, Ricardo e Fernanda) e os observaremos realizando tarefas representativas no protótipo. Este método é ideal para:<br>- Identificar problemas reais de uso em contexto.<br>- Coletar dados objetivos (tempo de conclusão, taxa de erro, número de cliques).<br>- Coletar dados subjetivos (satisfação, confiança, frustração).<br>- Validar se as métricas técnicas são compreensíveis para diferentes perfis.<br><br>**2. Avaliação Heurística (Método de Inspeção):**<br>Avaliadores especializados (colegas da equipe ou da disciplina) usarão um formulário estruturado com as **10 Heurísticas de Nielsen** para:<br>- Identificar violações de princípios de usabilidade.<br>- Classificar problemas por gravidade (cosmético, leve, grave, catastrófico).<br>- Avaliar consistência da interface.<br>- Verificar prevenção de erros e qualidade das mensagens de feedback. |
| **I** | **Identificar e administrar as questões práticas:**<br><br>Este é o plano de execução detalhado da avaliação:<br><br>**1. Artefato a ser Avaliado:**<br>Protótipo navegável de média/alta fidelidade da interface PyQt5 para testes de modelos de IA.<br><br>**2. Participantes (Teste de Usabilidade):**<br>Recrutar **6 participantes**:<br>- **2 Engenheiros de ML** (perfil Paulo Andrade) - experiência com PyTorch, YOLO, frameworks de IA.<br>- **2 Gerentes de Segurança** (perfil Ricardo Santos) - conhecimento em NRs, familiaridade com dashboards.<br>- **2 Gestoras de Projetos** (perfil Fernanda Costa) - experiência em gestão de projetos de inovação, apresentações executivas.<br><br>**3. Avaliadores (Avaliação Heurística):**<br>3-4 avaliadores especializados (colegas da disciplina ou profissionais de IHC).<br><br>**4. Local:**<br>- **Testes com usuários:** Sala de reunião silenciosa com computador equipado com GPU NVIDIA (simulando ambiente real de uso).<br>- **Avaliação heurística:** Pode ser remota, com acesso ao protótipo.<br><br>**5. Duração:**<br>- Teste individual: 45-60 minutos por participante.<br>- Avaliação heurística: 2-3 horas por avaliador.<br><br>**6. Roteiro de Tarefas (Scripts):**<br>Serão criadas **3 tarefas principais** baseadas nos cenários de interação:<br><br>**Tarefa 1 (Engenheiro de ML - Paulo):**<br>"Você recebeu um novo modelo YOLOv8 treinado para detectar EPIs. Configure o modelo no sistema, defina um limite de confiança de 0.85, selecione o uso de GPU, faça o upload de um vídeo de teste e execute a análise. Ao final, ordene as métricas por desempenho e identifique qual classe teve melhor precisão."<br><br>**Tarefa 2 (Gerente de Segurança - Ricardo):**<br>"A equipe técnica executou testes com 3 modelos diferentes na última semana. Acesse o Painel de Resultados, selecione o relatório do modelo 'YOLOv8_EPIs_v2', analise as métricas de desempenho apresentadas (especialmente taxa de detecção de EPIs e falsos negativos) e exporte o relatório em CSV para apresentar na reunião de segurança."<br><br>**Tarefa 3 (Gestora de Projetos - Fernanda):**<br>"Você precisa preparar uma apresentação para a diretoria sobre o andamento do projeto de IA. Acesse o Painel de Resultados, consulte os relatórios dos últimos 30 dias, identifique qual modelo teve o melhor desempenho geral e exporte os dados consolidados em CSV para criar gráficos comparativos."<br><br>**7. Lista de Instrumentos:**<br><br>**a) Termo de Consentimento Livre e Esclarecido (TCLE):**<br>- Apresentado antes do início do teste.<br>- Explica objetivos, procedimentos, riscos, benefícios.<br>- Garante anonimato e direito de desistência.<br>- Solicita autorização para gravação (opcional).<br><br>**b) Questionário Pré-Teste:**<br>- Perfil demográfico e profissional.<br>- Experiência com IA, visão computacional e ferramentas de teste.<br>- Familiaridade com métricas (precisão, recall, mAP).<br>- Expectativas sobre o sistema.<br><br>**c) Tabela de Observação (Roteiro de Acompanhamento):**<br>- Registra comportamentos durante a execução das tarefas.<br>- Anota erros, hesitações, expressões de frustração.<br>- Mede tempo de conclusão de cada tarefa.<br>- Registra número de cliques/ações desnecessárias.<br>- Identifica momentos de dúvida ou pedidos de ajuda.<br><br>**d) Questionário Pós-Teste:**<br>- Escala de satisfação (Likert 1-5).<br>- Perguntas sobre facilidade de uso.<br>- Identificação de pontos de frustração.<br>- Sugestões de melhoria.<br>- Questões abertas sobre a experiência geral.<br><br>**e) Formulário de Avaliação Heurística:**<br>- Lista das 10 Heurísticas de Nielsen.<br>- Escala de gravidade dos problemas (0-4).<br>- Espaço para descrição detalhada de cada problema.<br>- Sugestões de correção. |
| **D** | **Decidir como lidar com as questões éticas:**<br><br>Os seguintes cuidados éticos serão rigorosamente observados:<br><br>**1. Termo de Consentimento Livre e Esclarecido (TCLE):**<br>Todos os participantes dos testes com usuários deverão ler e assinar o TCLE antes de iniciar a avaliação. O documento conterá:<br>- Objetivo acadêmico do projeto.<br>- Descrição dos procedimentos do teste.<br>- Tempo estimado de participação.<br>- Riscos mínimos (desconforto, cansaço).<br>- Benefícios (contribuir para melhoria da segurança do trabalho).<br>- Garantia de anonimato e confidencialidade.<br><br>**2. Princípio da Autonomia:**<br>- Participação totalmente **voluntária**.<br>- Direito de desistir a qualquer momento sem justificativa ou prejuízo.<br>- Possibilidade de pular questões desconfortáveis.<br>- Autorização explícita para gravação de áudio/vídeo (se aplicável).<br><br>**3. Princípio da Não Maleficência e Beneficência:**<br>- Será explicado verbalmente antes do teste: **"Estamos testando o sistema, não você"**.<br>- Evitar constrangimento ou pressão sobre o participante.<br>- Garantir que o tempo dedicado seja respeitado (máximo 60 minutos).<br>- Ambiente confortável e livre de interrupções.<br><br>**4. Privacidade e Confidencialidade:**<br>- Dados coletados (gravações, logs, questionários) serão **anonimizados**.<br>- Identificadores genéricos serão usados no relatório (ex: "Participante E1" para Engenheiro 1, "Participante G1" para Gerente 1, "Participante GP1" para Gestora de Projetos 1).<br>- Armazenamento seguro com acesso restrito à equipe de pesquisa.<br>- Dados usados exclusivamente para fins acadêmicos.<br>- Destruição dos dados após conclusão do projeto (conforme LGPD).<br><br>**5. Princípio da Justiça e Equidade:**<br>- Seleção justa de participantes sem discriminação.<br>- Todos os perfis de usuário devem ser representados.<br>- Resultados devem beneficiar todos os usuários futuros do sistema.<br>- Feedback será compartilhado com os participantes interessados. |
| **E** | **Avaliar (Interpretar e Apresentar os Dados):**<br><br>A análise e produção dos resultados seguirá um processo estruturado:<br><br>**1. Coleta e Organização dos Dados:**<br><br>**Dados Quantitativos:**<br>- Taxa de conclusão de tarefas (% de sucesso).<br>- Tempo médio para concluir cada tarefa.<br>- Número de erros cometidos.<br>- Número de cliques/ações realizadas.<br>- Scores de satisfação (escala Likert).<br><br>**Dados Qualitativos:**<br>- Comentários durante o teste (protocolo think-aloud).<br>- Respostas abertas dos questionários.<br>- Observações do avaliador (expressões, hesitações).<br>- Sugestões de melhoria dos participantes.<br><br>**2. Interpretação dos Dados:**<br><br>**Análise dos Testes com Usuários:**<br>- Compilar dados das **Tabelas de Observação** para calcular:<br>  - Taxa de sucesso por tarefa e por perfil de usuário.<br>  - Tempo médio e desvio padrão.<br>  - Principais pontos de dificuldade (heatmap de erros).<br>- Transcrever e categorizar comentários qualitativos.<br>- Identificar padrões de comportamento por persona.<br><br>**Análise da Avaliação Heurística:**<br>- Consolidar problemas encontrados por múltiplos avaliadores.<br>- Classificar por heurística violada.<br>- Priorizar por gravidade (escala 0-4 de Nielsen).<br>- Calcular concordância entre avaliadores.<br><br>**3. Consolidação e Priorização:**<br>- **Triangulação:** Cruzar problemas encontrados nos testes com usuários e na avaliação heurística.<br>- **Lista Unificada de Problemas:** Consolidar todos os problemas identificados.<br>- **Priorização por Gravidade:**<br>  - **Crítico (P0):** Impede conclusão da tarefa, afeta todos os usuários.<br>  - **Alto (P1):** Causa grande frustração, afeta maioria dos usuários.<br>  - **Médio (P2):** Causa inconveniência, afeta alguns usuários.<br>  - **Baixo (P3):** Problema cosmético, não afeta funcionalidade.<br><br>**4. Recomendações de Reprojeto:**<br>Para cada problema identificado, propor:<br>- Descrição detalhada do problema.<br>- Evidências (dados quantitativos, citações de usuários).<br>- Impacto na experiência do usuário.<br>- Sugestão de solução de design.<br>- Prioridade de implementação.<br><br>**5. Relato dos Resultados:**<br>Será produzido um **relatório final** contendo:<br><br>**Estrutura do Relatório:**<br>1. **Sumário Executivo**<br>   - Principais achados.<br>   - Problemas críticos identificados.<br>   - Recomendações prioritárias.<br><br>2. **Introdução**<br>   - Objetivos da avaliação.<br>   - Contexto do projeto.<br><br>3. **Metodologia**<br>   - Métodos escolhidos (testes + heurísticas).<br>   - Perfil dos participantes.<br>   - Procedimentos de coleta de dados.<br><br>4. **Resultados**<br>   - Dados quantitativos (tabelas, gráficos).<br>   - Dados qualitativos (citações, observações).<br>   - Análise por tarefa e por persona.<br><br>5. **Lista de Problemas Encontrados**<br>   - Problemas priorizados por gravidade.<br>   - Evidências e descrição detalhada.<br><br>6. **Recomendações para o Reprojeto**<br>   - Sugestões de melhorias por prioridade.<br>   - Mockups/wireframes (se aplicável).<br><br>7. **Conclusão**<br>   - Síntese dos achados.<br>   - Próximos passos.<br><br>8. **Anexos**<br>   - Instrumentos utilizados (TCLE, questionários, tabelas).<br>   - Dados brutos anonimizados. |

---
